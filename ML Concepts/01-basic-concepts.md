

01) Difference between Gradient Descent and Stochastic Gradient Descent? Is SGD faster than GD? 
    Why don't we always use it in that case

GD: it is slow, requires high memory and in general good for small data sets. 
SGD: it is fast, requires low memory and in general good for big data sets 

GD will always find better minima than SGD, however will take longer to converge.



02 )  What is a difference between supervised and unsupervised learning? Give an example of both.
 
03 ) How SVM algorithm works (general description)? 

04 ) How to make sure you are not overfitting while training a model? 

05 )  How do you measure accuracy or the error rates?